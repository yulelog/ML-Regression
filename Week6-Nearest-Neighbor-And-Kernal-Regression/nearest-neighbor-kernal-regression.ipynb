{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beneficial-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "according-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data_small.csv')\n",
    "train = pd.read_csv('kc_house_data_small_train.csv')\n",
    "validation = pd.read_csv('kc_house_data_validation.csv')\n",
    "test = pd.read_csv('kc_house_data_small_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparable-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, features, output):\n",
    "    df['constant'] = 1 \n",
    "    features = ['constant'] + features\n",
    "    features_df = df[features]\n",
    "    \n",
    "    feature_matrix = features_df.to_numpy()\n",
    "    output_array = df['price'].to_numpy()\n",
    "\n",
    "    return feature_matrix, output_array\n",
    "\n",
    "\n",
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    normalize columns of a given feature matrix.\n",
    "    :param features: columns of a feature matrix\n",
    "    :return normalized features: normalized columns of given feature matrix\n",
    "    :return norms: norms of orignal features\n",
    "    \"\"\"\n",
    "    \n",
    "    norms = np.linalg.norm(features, axis=0)\n",
    "    normalized_features = features / norms\n",
    "    \n",
    "    return normalized_features, norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy arrays\n",
    "feature_list = [\n",
    "    'bedrooms',  \n",
    "    'bathrooms',  \n",
    "    'sqft_living',  \n",
    "    'sqft_lot',  \n",
    "    'floors',\n",
    "    'waterfront',  \n",
    "    'view',  \n",
    "    'condition',  \n",
    "    'grade',  \n",
    "    'sqft_above',  \n",
    "    'sqft_basement',\n",
    "    'yr_built',  \n",
    "    'yr_renovated',  \n",
    "    'lat',  \n",
    "    'long',  \n",
    "    'sqft_living15',  \n",
    "    'sqft_lot15'\n",
    "]\n",
    "\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "features_train, norms = normalize_features(features_train)\n",
    "features_test = features_test / norms\n",
    "features_valid = features_valid / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-hartford",
   "metadata": {},
   "source": [
    "#### Compute a single distance\n",
    "\n",
    "To start, let's just explore computing the “distance” between two given houses. We will take our query house to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1. Similarly, print the 10th row (index 9) of the training feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query house: \n",
      " [ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059\n",
      "  0.          0.05102365  0.0116321   0.01564352  0.01362084  0.02481682\n",
      "  0.01350306  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n",
      "House in training set: \n",
      " [ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n"
     ]
    }
   ],
   "source": [
    "print(\"Query house: \\n\", features_test[0])\n",
    "print(\"House in training set: \\n\", features_train[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afraid-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05972359371398078"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Euclidean Distance\n",
    "np.sqrt(np.sum((features_test[0] - features_train[9])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-prevention",
   "metadata": {},
   "source": [
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (features_test[0]) to the first 10 houses of the training set (features_train[0:10]) and then search for the nearest neighbor within this small set of houses.  Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "harmful-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to house 0 0.06027470916295592\n",
      "Distance to house 1 0.08546881147643746\n",
      "Distance to house 2 0.06149946435279315\n",
      "Distance to house 3 0.05340273979294363\n",
      "Distance to house 4 0.05844484060170442\n",
      "Distance to house 5 0.059879215098128345\n",
      "Distance to house 6 0.05463140496775461\n",
      "Distance to house 7 0.055431083236146074\n",
      "Distance to house 8 0.052383627840220305\n",
      "Distance to house 9 0.05972359371398078\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Distance to house {i}\", np.sqrt(np.sum((features_test[0] - features_train[i])**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-clear",
   "metadata": {},
   "source": [
    "#### Perform 1-nearest neighbor regression\n",
    "Write a single-line expression to define a variable ‘diff’ such that ‘diff[i]’ gives the element-wise difference between the features of the query house and the i-th training house.(Using vectorized numpy functions).\n",
    "\n",
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in ‘diff’, square each, and take the sum over feature indices.  That is, compute the sum of squared feature differences for each training house (row in ‘diff’).\n",
    "\n",
    "By default, ‘np.sum’ sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the ‘axis’ parameter described in the np.sum documentation. In particular, ‘axis=1’ computes the sum across each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "significant-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(features_instances, features_query):\n",
    "    diff = features_instances - features_query\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "parental-immunology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_distances(features_train[4], features_test[2])\n",
    "# np.sum((features_train[4] - features_test[2])**1, axis=1)\n",
    "# features_train[4].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "subjective-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest neighbor:  (array([382]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "249000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the query house to be third house of the test set (features_test[2]).  \n",
    "# What is the index of the house in the training set that is closest to this query house?\n",
    "quiz_distance = compute_distances(features_train, features_test[2])\n",
    "print(\"Closest neighbor: \", np.where(quiz_distance == min(quiz_distance)))\n",
    "# What is the predicted value of the query house based on 1-nearest neighbor regression?\n",
    "output_train[382]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-hierarchy",
   "metadata": {},
   "source": [
    "#### Perform k-nearest neighbor regression\n",
    "Using the functions above, implement a function that takes in:\n",
    "- the value of k;\n",
    "- the feature matrix for the instances; and\n",
    "- the feature of the query\n",
    "- and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "progressive-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, feature_train, features_query):\n",
    "    # initialize\n",
    "    dist2kNN = np.sort(compute_distances(feature_train[:k], features_query))\n",
    "    neighbors = np.argsort(dist2kNN)\n",
    "    \n",
    "    for i in range(k, len(feature_train)):\n",
    "        new_distance = compute_distances(feature_train[i].reshape(1,-1), features_query)\n",
    "        if new_distance < dist2kNN[k-1]:\n",
    "            # find j such that δ > dist2kNN[j-1] but δ < dist2kNN[j]\n",
    "            j = max(np.max(np.where(dist2kNN < new_distance), initial=0), np.min(np.where(dist2kNN > new_distance)))\n",
    "            # remove furthest house and shift queue\n",
    "            neighbors[j+1:k] = neighbors[j:k-1]\n",
    "            dist2kNN[j+1:k] = dist2kNN[j:k-1]\n",
    "            # set the new distance at j\n",
    "            dist2kNN[j] = new_distance\n",
    "            neighbors[j] = i\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cooked-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 382, 1149, 4087, 3142])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the query house to be third house of the test set (features_test[2]).  \n",
    "# What are the indices of the 4 training houses closest to the query house?\n",
    "k_nearest_neighbors(4, features_train, features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-observation",
   "metadata": {},
   "source": [
    "Write a function that predicts the value of a given query house. For simplicity, take the average of the prices of the k nearest neighbors in the training set. The function should have the following parameters:\n",
    "- the value of k;\n",
    "- the feature matrix for the instances;\n",
    "- the output values (prices) of the instances; and\n",
    "- the feature of the query, whose price we’re predicting.\n",
    "- The function should return a predicted value of the query house.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "industrial-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    neighbors = k_nearest_neighbors(k, features_train, features_query)\n",
    "    prediction = 1/k * np.sum(output_train[neighbors])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "quantitative-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again taking the query house to be third house of the test set (features_test[2]), \n",
    "# predict the value of the query house using k-nearest neighbors with k=4 \n",
    "# and the simple averaging method described and implemented above.\n",
    "predict_output_of_query(4, features_train, output_train, features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-august",
   "metadata": {},
   "source": [
    "Finally, write a function to predict the value of each and every house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    "- the value of k;\n",
    "- the feature matrix for the training set;\n",
    "- the output values (prices) of the training houses; and\n",
    "- the feature matrix for the query set.\n",
    "- The function should return a set of predicted values, one for each house in the query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "heavy-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(k, features_train, output_train, features_query):\n",
    "    predictions = np.array([predict_output_of_query(k, features_train, output_train, i) for i in features_query])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "treated-inventory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([881300. , 431860. , 460595. , 430200. , 766750. , 667420. ,\n",
       "       350032. , 512800.7, 484000. , 457235. ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the first 10 houses in the test set, using k=10. \n",
    "# What is the index of the house in this query set that has the lowest predicted value?  \n",
    "# What is the predicted value of this house?\n",
    "predict_output(10, features_train, output_train, features_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-substance",
   "metadata": {},
   "source": [
    "#### Choosing the best value of k using a validation set\n",
    "\n",
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "For k in [1, 2, … 15]:\n",
    "- Make predictions for the VALIDATION data using the k-nearest neighbors from the TRAINING data.\n",
    "- Compute the RSS on VALIDATION data\n",
    "- Report which k produced the lowest RSS on validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "suited-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "smallest_rss = math.inf\n",
    "\n",
    "for k in range(1, 16):\n",
    "    print(k)\n",
    "    predictions_valid = predict_output(k, features_train, output_train, features_valid)\n",
    "    rss = sum((output_valid-predictions_valid)**2)\n",
    "    if rss < smallest_rss:\n",
    "        smallest_rss = rss\n",
    "        best_k = k\n",
    "\n",
    "print(best_k)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "continent-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133154528199016.81\n"
     ]
    }
   ],
   "source": [
    "# What is the RSS on the TEST data using the value of k found above?  \n",
    "# To be clear, sum over all houses in the TEST set.\n",
    "predictions_test = predict_output(8, features_train, output_train, features_test)\n",
    "rss = sum((output_test-predictions_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "particular-climate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.331545e+14'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:e}\".format(rss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
