{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wrapped-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-sense",
   "metadata": {},
   "source": [
    "### Observing effects of L2 penalty in polynomial regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "measured-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copyied from previous module\n",
    "\n",
    "def polynomial_dataframe(feature, degree): \n",
    "    \"\"\"\n",
    "    Takes an array of 'feature' and a maximal 'degree', \n",
    "    and return a data frame with the first column equal to 'feature'\n",
    "    and the remaining columns equal to ‘feature’ to increasing integer powers up to 'degree'\n",
    "    :param feature: pandas Series\n",
    "    :param degree: int >=1\n",
    "    :return : a dataframe of the feature columns\n",
    "    \"\"\"\n",
    "    poly_dataframe = pd.DataFrame()\n",
    "    poly_dataframe['power_1'] = feature\n",
    "\n",
    "    if degree > 1:\n",
    "        for power in range(2, degree+1):\n",
    "            name = 'power_' + str(power)\n",
    "            poly_dataframe[name] = feature.apply(lambda x: x**power)\n",
    "    return poly_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paperback-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "sales = sales.sort_values(['sqft_living','price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-population",
   "metadata": {},
   "source": [
    "Create a 15th-order polynomial model fitted with an L2 penalty of 1.5e-5 (Regularization would make the solution numerically stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-fifth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_small_penalty = 1.5e-5\n",
    "poly15_data = polynomial_dataframe(sales['sqft_living'], 15)\n",
    "model = linear_model.Ridge(alpha=l2_small_penalty, normalize=True)\n",
    "model.fit(poly15_data, sales['price'])\n",
    "round(model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-mapping",
   "metadata": {},
   "source": [
    "Observe Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "portable-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = pd.read_csv('wk3_kc_house_set_1_data.csv', dtype=dtype_dict)\n",
    "set_2 = pd.read_csv('wk3_kc_house_set_2_data.csv', dtype=dtype_dict)\n",
    "set_3 = pd.read_csv('wk3_kc_house_set_3_data.csv', dtype=dtype_dict)\n",
    "set_4 = pd.read_csv('wk3_kc_house_set_4_data.csv', dtype=dtype_dict)\n",
    "l2_small_penalty=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "severe-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ridge_coefficient(df, penalty):\n",
    "    poly15_data = polynomial_dataframe(df['sqft_living'], 15)\n",
    "    model = linear_model.Ridge(alpha=penalty, normalize=True)\n",
    "    model.fit(poly15_data, df['price'])\n",
    "    print(model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "electric-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544.6693903291846\n",
      "859.3626475978917\n",
      "-755.3959047401938\n",
      "1119.4457483861213\n"
     ]
    }
   ],
   "source": [
    "for df in [set_1, set_2, set_3, set_4]:\n",
    "    get_ridge_coefficient(df, l2_small_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-printer",
   "metadata": {},
   "source": [
    "Ridge regression comes to rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "competent-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.328068029579326\n",
      "2.097569027778555\n",
      "2.289062581189205\n",
      "2.0859619409193066\n"
     ]
    }
   ],
   "source": [
    "l2_large_penalty=1.23e2\n",
    "for df in [set_1, set_2, set_3, set_4]:\n",
    "    get_ridge_coefficient(df, l2_large_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-compilation",
   "metadata": {},
   "source": [
    "Selecting an L2 penalty via cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranking-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_shuffled = pd.read_csv('wk3_kc_house_train_valid_shuffled.csv', dtype=dtype_dict)\n",
    "test = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "confused-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k, l2_penalty, data, output):\n",
    "    \"\"\"\n",
    "    :param k: number of validation sets\n",
    "    :param l2_penalty: \n",
    "    :param data: dataframe containing input features\n",
    "    :param output: column of output values (e.g. price). \n",
    "    :return : average validation error\n",
    "    \"\"\"\n",
    "    validation_error = 0\n",
    "    for i in range(k):\n",
    "        # Compute starting and ending indices of segment i\n",
    "        start = round((n*i)/10)\n",
    "        end = round((n*(i+1))/10)\n",
    "        \n",
    "        # Form validation set by taking a slice (start:end+1) from the data\n",
    "        validation_set = data[start:end+1]\n",
    "        validation_output = output[start:end+1]\n",
    "        \n",
    "        # Form training set by appending slice (end+1:n) to the end of slice (0:start).\n",
    "        training_set = data[0:start].append(data[end+1:n])\n",
    "        training_output = output[0:start].append(output[end+1:n])\n",
    "        \n",
    "        # Train a linear model using training set just formed, with a given l2_penalty\n",
    "        model = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "        model.fit(training_set, training_output)\n",
    "        \n",
    "        # Compute validation error (RSS) using validation set just formed\n",
    "        rss = sum((model.predict(validation_set) - validation_output)**2)\n",
    "        \n",
    "        validation_error += rss\n",
    "    \n",
    "    return validation_error/k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-station",
   "metadata": {},
   "source": [
    " Once we have a function to compute the average validation error for a model, we can write a loop to find the model that minimizes the average validation error. Write a loop that does the following:\n",
    "\n",
    "- We will again be aiming to fit a 15th-order polynomial model using the sqft_living input\n",
    "- For each l2_penalty in [10^3, 10^3.5, 10^4, 10^4.5, ..., 10^9] (to get this in Python, you can use this Numpy function: np.logspace(3, 9, num=13).): Run 10-fold cross-validation with l2_penalty.\n",
    "- Report which L2 penalty produced the lowest average validation error.\n",
    "\n",
    "Note: since the degree of the polynomial is now fixed to 15, to make things faster, you should generate polynomial features in advance and re-use them throughout the loop. Make sure to use train_valid_shuffled when generating polynomial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "infinite-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly15_data = polynomial_dataframe(train_valid_shuffled['sqft_living'], 15)\n",
    "penalties = np.logspace(3, 9, num=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adequate-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for penalty in penalties:\n",
    "    result.append({\"penalty\": penalty, \"error\": k_fold_cross_validation(10, penalty, poly15_data, train_valid_shuffled['price'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dress-prisoner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result).sort_values(\"error\").iloc[0][\"penalty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-electric",
   "metadata": {},
   "source": [
    "Retrain a final model on all of the training data using this best l2_penalty value that yield smalles validation error. Then use this l2_penalty value to train a model using all training data, and find the RSS on the TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fourth-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.837569e+14'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('wk3_kc_house_train_data.csv')\n",
    "test_data = pd.read_csv('wk3_kc_house_test_data.csv')\n",
    "\n",
    "poly15_train_data = polynomial_dataframe(train_data['sqft_living'], 15)\n",
    "model = linear_model.Ridge(alpha=1000, normalize=True)\n",
    "model.fit(poly15_train_data, train_data['price'])\n",
    "\n",
    "poly15_test_data = polynomial_dataframe(test_data['sqft_living'], 15)\n",
    "\"{:e}\".format(sum((model.predict(poly15_test_data) - test_data['price'])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-burton",
   "metadata": {},
   "source": [
    "### Implementing ridge regression via gradient descent ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "drawn-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions copied from multiple regression module\n",
    "\n",
    "def get_numpy_data(df, features, output):\n",
    "    \"\"\"\n",
    "    Takes a data set df, a list of features, and a output name, \n",
    "    return a 2D array of feature matrix and 1D array of output\n",
    "    :param df: pandas dataframe of the data set\n",
    "    :param features: list of the feature names to be selected\n",
    "    :param output: name of the output\n",
    "    :return features_matrix: a 2D features_matrix including an additional column of 1s as the constant feature\n",
    "    :return output_array: a 1D array of output\n",
    "    \"\"\"\n",
    "    # add a constant column\n",
    "    df['constant'] = 1 \n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    \n",
    "    # convert the features into a numpy matrix\n",
    "    features_matrix = df[features].to_numpy()\n",
    "    # convert the pandas Series into a numpy array\n",
    "    output_array = df[output].to_numpy()\n",
    "    output_array = output_array.reshape(output_array.shape[0],1)\n",
    "    \n",
    "    return features_matrix, output_array\n",
    "\n",
    "\n",
    "def predict_outcome(feature_matrix, weights):\n",
    "    \"\"\"\n",
    "    Predict outcome based on the feature matrix and weights given\n",
    "    :param feature_matrix: 2D matrix of features with a shape of N observations * D features (N*D)\n",
    "    :param weights: 1D array of weights with D features (D*1)\n",
    "    :return predictions: 1D array of N predicted outcome (N*1)\n",
    "    \"\"\"\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    predictions = predictions.reshape(predictions.shape[0],1)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "intellectual-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative_ridge(errors, feature, weight, l2_penalty, feature_is_constant):\n",
    "    \n",
    "    # Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. \n",
    "    # Therefore the derivative for the weight for feature_i is just two times the dot product between the values \n",
    "    # of feature_i and the current errors, plus 2*l2_penalty*w[i].\n",
    "    \n",
    "    derivative = 2*np.dot(feature, errors)\n",
    "    if feature_is_constant == False:\n",
    "        derivative = derivative + np.array(2*l2_penalty*weight)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-drill",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of increase and therefore the negative gradient is the direction of decrease and we're trying to minimize a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient direction is called the ‘step size’. We stop when we are ‘sufficiently close’ to the optimum. Unlike in Module 2, this time we will set a maximum number of iterations and take gradient steps until we reach this maximum number. If no maximum number is supplied, the maximum should be set 100 by default. (Use default parameter values in Python.)\n",
    "\n",
    "With this in mind, write a gradient descent function using your derivative function above. For each step in the gradient descent, we update the weight for each feature before computing our stopping criteria.  The function will take the following parameters:\n",
    "\n",
    "- 2D feature matrix\n",
    "- array of output values\n",
    "- initial weights\n",
    "- step size\n",
    "- L2 penalty\n",
    "- maximum number of iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "rational-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty, max_iterations=100):\n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    t = 0  # initiate iterations\n",
    "    \n",
    "    while t < max_iterations:\n",
    "        #while not reached maximum number of iterations:\n",
    "        # compute the predictions using your predict_output() function\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        \n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:,i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i].\n",
    "            #(Remember: when i=0, you are computing the derivative of the constant!)\n",
    "            feature_is_constant = True if i == 0 else False\n",
    "            derivative = feature_derivative_ridge(errors, feature_matrix[:,i], weights[i], l2_penalty, feature_is_constant)\n",
    "\n",
    "            # subtract the step size times the derivative from the current weight  \n",
    "            weights[i] = weights[i] - step_size*derivative\n",
    "        \n",
    "        t = t + 1\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "jewish-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Single Feature Model with 'sqft_living' ###\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "simple_feature_matrix, output = get_numpy_data(train_data, simple_features, my_output)\n",
    "simple_test_feature_matrix, test_output = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "approved-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No regularization\n",
    "simple_weights_0_penalty = ridge_regression_gradient_descent(\n",
    "    simple_feature_matrix, output, np.array([0.,0.]), 1e-12, 0.0, 1000)\n",
    "\n",
    "# Regularization with L2 penalty at 1e11\n",
    "simple_weights_high_penalty = ridge_regression_gradient_descent(\n",
    "    simple_feature_matrix, output, np.array([0.,0.]), 1e-12, 1e11, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "mighty-tsunami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb0c99a9340>,\n",
       " <matplotlib.lines.Line2D at 0x7fb0c99a9400>,\n",
       " <matplotlib.lines.Line2D at 0x7fb0c99a91c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fb0c99a95b0>,\n",
       " <matplotlib.lines.Line2D at 0x7fb0c99a9370>,\n",
       " <matplotlib.lines.Line2D at 0x7fb0c99a9730>]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(simple_feature_matrix,output,'k.',\n",
    "        simple_feature_matrix,predict_outcome(simple_feature_matrix, simple_weights_0_penalty),'b-',\n",
    "        simple_feature_matrix,predict_outcome(simple_feature_matrix, simple_weights_high_penalty),'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "optional-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model with two features ###\n",
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output = 'price'\n",
    "feature_matrix, output = get_numpy_data(train_data, model_features, my_output)\n",
    "test_feature_matrix, test_output = get_numpy_data(test_data, model_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "magnetic-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_weights_0_penalty = ridge_regression_gradient_descent(\n",
    "    feature_matrix, output, np.array([0.,0.,0.]), 1e-12, 0, 1000)\n",
    "multiple_weights_high_penalty = ridge_regression_gradient_descent(\n",
    "    feature_matrix, output, np.array([0.,0.,0.]), 1e-12, 1e11, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
